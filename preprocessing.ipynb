{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import librosa as librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import time\n",
    "import gc\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6898 cycles\n",
      "There are 920 samples\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'data/Respiratory_Sound_Database/audio_and_txt_files'\n",
    "text_files = glob.iglob(directory_path + '/*.txt', recursive=True)\n",
    "text_files_list = list(text_files)\n",
    "\n",
    "dfs = []\n",
    "for file in text_files_list:\n",
    "    content = pd.read_csv(file, names = [\"start_time\", \"end_time\", \"crackles\", \"wheezes\"], delimiter = \"\\t\")\n",
    "    patient_number = file.split(\"_\")[5][6:]\n",
    "    content['patient'] = int(patient_number)\n",
    "    dfs.append(content)\n",
    "samples = pd.concat(dfs)\n",
    "\n",
    "print(\"There are\", len(samples), \"cycles\")\n",
    "print(\"There are\", len(text_files_list), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new directories to be created\n",
    "spectrograms_path = \"data/spectrograms\"\n",
    "clips_by_cycle_path = \"data/Respiratory_Sound_Database/clips_by_cycle\"\n",
    "\n",
    "# create the directories\n",
    "os.makedirs(spectrograms_path, exist_ok=True)\n",
    "os.makedirs(clips_by_cycle_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of data/spectrograms cleared.\n",
      "Contents of data/Respiratory_Sound_Database/clips_by_cycle cleared.\n"
     ]
    }
   ],
   "source": [
    "# clear output of folders created above\n",
    "output_folders = ['data/spectrograms','data/Respiratory_Sound_Database/clips_by_cycle']\n",
    "for folder in output_folders:\n",
    "    for file_name in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        # Remove the file\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "    print(f\"Contents of {folder} cleared.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'data/spectrograms'\n",
    "# converts file, where file is a string (name of the file), into a string with the given format, where format is a string\n",
    "# assumes the format already in the file is 3 characters long\n",
    "# if cycle > 0, it adds \"cycle _\" to the end of the file name before the ending\n",
    "# if cycle = 0, it leaves the rest of the file as is\n",
    "def convert_type(file, format, cycle):\n",
    "    if cycle > 0:\n",
    "        file = file[0:len(file)-4] + \"_cycle\" + str(cycle) + \".\" + format\n",
    "    else:\n",
    "        file = file[0:len(file)-3] + format\n",
    "    return file\n",
    "\n",
    "\n",
    "# divide audio_file into its respiratory cycles\n",
    "# takes the name of the audio file (.wav) as a string as the argument\n",
    "def divide_into_cycles(audio_file_name):\n",
    "    # take just the timestamps for the respiratory cycles- ignore crackles and wheezes\n",
    "    audio_file_name_as_txt = directory_path + \"/\" + convert_type(audio_file_name, \"txt\", 0)\n",
    "    timestamps = np.loadtxt(audio_file_name_as_txt, delimiter='\\t')\n",
    "    timestamps = timestamps[:, :2]\n",
    "    \n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def generate_spectrogram(audio_file):\n",
    "    # load the audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    \n",
    "    audio_file_name = os.path.basename(audio_file)\n",
    "    # find where the timestamps of audio_file are\n",
    "    timestamps = divide_into_cycles(audio_file_name) # list\n",
    "    \n",
    "    # find the length of the shortest spectrogram\n",
    "    min = -1\n",
    "    for cycle in timestamps:\n",
    "        start_time = cycle[0]\n",
    "        end_time = cycle[1]\n",
    "        length = end_time - start_time\n",
    "        if min == -1 or length < min:\n",
    "            min = length\n",
    "    \n",
    "    # make a mel db spectrogram for each respiratory cycle using the timestamps\n",
    "    cycle_number = 1\n",
    "    for cycle in timestamps:\n",
    "        # take the portion of the audio that contains this respiratory cycle\n",
    "\n",
    "        # start and end time in seconds\n",
    "        start_time = cycle[0]\n",
    "        end_time = cycle[1]\n",
    "        \n",
    "        # determine how much of the audio segment we need to crop\n",
    "        diff = (end_time - start_time) - min\n",
    "        crop_amt = int(diff / 2)\n",
    "        \n",
    "        # convert the start and end times to sample indices\n",
    "        start_sample = int(start_time * sr) + crop_amt\n",
    "        end_sample = int(end_time * sr) - crop_amt\n",
    "        \n",
    "        # extract the audio segment\n",
    "        audio_segment = y[start_sample:end_sample]\n",
    "        \n",
    "        spectrogram_name = convert_type(audio_file_name, \"jpg\", cycle_number)\n",
    "        \n",
    "        # make the mel db spectrogram based on that audio segment\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_segment, n_fft=2048, hop_length=512)), ref=np.max)\n",
    "        # display the spectrogram\n",
    "        plt.figure(figsize=(5, 2))\n",
    "        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        plt.subplots_adjust(left=0, right=1, top=1, bottom=0) # removes the white space around the spectrogram\n",
    "        # plt.colorbar(format='%+2.0f dB')\n",
    "        # plt.title(spectrogram_name)\n",
    "\n",
    "        # save the spectrogram to the output folder\n",
    "        output_path = os.path.join(output_folder, spectrogram_name)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        cycle_number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets all audio files\n",
    "audio_files = glob.iglob(directory_path + '/*.wav', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 files so far in 5.674891710281372 seconds\n",
      "Processed 20 files so far in 10.246279001235962 seconds\n",
      "Processed 30 files so far in 14.733537673950195 seconds\n",
      "Processed 40 files so far in 18.451191902160645 seconds\n",
      "Processed 50 files so far in 22.335641860961914 seconds\n",
      "Processed 60 files so far in 26.07521390914917 seconds\n",
      "Processed 70 files so far in 29.876194715499878 seconds\n",
      "Processed 80 files so far in 33.86075973510742 seconds\n",
      "Processed 90 files so far in 37.893085956573486 seconds\n",
      "Processed 100 files so far in 42.63920283317566 seconds\n",
      "Processed 110 files so far in 46.93145775794983 seconds\n",
      "Processed 120 files so far in 50.89321303367615 seconds\n",
      "Processed 130 files so far in 54.67506790161133 seconds\n",
      "Processed 140 files so far in 58.32043981552124 seconds\n",
      "Processed 150 files so far in 62.3462347984314 seconds\n",
      "Processed 160 files so far in 67.47596883773804 seconds\n",
      "Processed 170 files so far in 71.68070673942566 seconds\n",
      "Processed 180 files so far in 75.66170191764832 seconds\n",
      "Processed 190 files so far in 80.5279188156128 seconds\n",
      "Processed 200 files so far in 84.20741486549377 seconds\n",
      "Processed 210 files so far in 89.14431190490723 seconds\n",
      "Processed 220 files so far in 92.98286890983582 seconds\n",
      "Processed 230 files so far in 98.0366039276123 seconds\n",
      "Processed 240 files so far in 102.22225904464722 seconds\n",
      "Processed 250 files so far in 106.71114706993103 seconds\n",
      "Processed 260 files so far in 111.6849308013916 seconds\n",
      "Processed 270 files so far in 116.62282490730286 seconds\n",
      "Processed 280 files so far in 120.83270573616028 seconds\n",
      "Processed 290 files so far in 126.08034896850586 seconds\n",
      "Processed 300 files so far in 130.87129592895508 seconds\n",
      "Processed 310 files so far in 135.40061378479004 seconds\n",
      "Processed 320 files so far in 139.7672278881073 seconds\n",
      "Processed 330 files so far in 144.18001985549927 seconds\n",
      "Processed 340 files so far in 148.65688490867615 seconds\n",
      "Processed 350 files so far in 153.8432319164276 seconds\n",
      "Processed 360 files so far in 158.28343510627747 seconds\n",
      "Processed 370 files so far in 162.68464994430542 seconds\n",
      "Processed 380 files so far in 167.18507504463196 seconds\n",
      "Processed 390 files so far in 172.8036708831787 seconds\n",
      "Processed 400 files so far in 177.30725288391113 seconds\n",
      "Processed 410 files so far in 181.84881782531738 seconds\n",
      "Processed 420 files so far in 187.21071481704712 seconds\n",
      "Processed 430 files so far in 192.70600771903992 seconds\n",
      "Processed 440 files so far in 197.80285501480103 seconds\n",
      "Processed 450 files so far in 202.26671171188354 seconds\n",
      "Processed 460 files so far in 207.03856492042542 seconds\n",
      "Processed 470 files so far in 211.73015189170837 seconds\n",
      "Processed 480 files so far in 217.24352288246155 seconds\n",
      "Processed 490 files so far in 221.73269367218018 seconds\n",
      "Processed 500 files so far in 226.52275109291077 seconds\n",
      "Processed 510 files so far in 231.16511178016663 seconds\n",
      "Processed 520 files so far in 235.92891192436218 seconds\n",
      "Processed 530 files so far in 242.19468688964844 seconds\n",
      "Processed 540 files so far in 247.08817172050476 seconds\n",
      "Processed 550 files so far in 251.79260802268982 seconds\n",
      "Processed 560 files so far in 256.4022150039673 seconds\n",
      "Processed 570 files so far in 262.0100507736206 seconds\n",
      "Processed 580 files so far in 266.9720559120178 seconds\n",
      "Processed 590 files so far in 271.51351976394653 seconds\n",
      "Processed 600 files so far in 276.57190465927124 seconds\n",
      "Processed 610 files so far in 281.27703499794006 seconds\n",
      "Processed 620 files so far in 286.101952791214 seconds\n",
      "Processed 630 files so far in 291.3675458431244 seconds\n",
      "Processed 640 files so far in 297.3568079471588 seconds\n",
      "Processed 650 files so far in 302.6326389312744 seconds\n",
      "Processed 660 files so far in 309.0380799770355 seconds\n",
      "Processed 670 files so far in 314.4361927509308 seconds\n",
      "Processed 680 files so far in 319.5956058502197 seconds\n",
      "Processed 690 files so far in 325.7128348350525 seconds\n",
      "Processed 700 files so far in 331.9385039806366 seconds\n",
      "Processed 710 files so far in 337.34641098976135 seconds\n",
      "Processed 720 files so far in 343.92098593711853 seconds\n",
      "Processed 730 files so far in 349.48744201660156 seconds\n",
      "Processed 740 files so far in 355.88223791122437 seconds\n",
      "Processed 750 files so far in 361.9398548603058 seconds\n",
      "Processed 760 files so far in 367.50896286964417 seconds\n",
      "Processed 770 files so far in 373.28138399124146 seconds\n",
      "Processed 780 files so far in 379.72839188575745 seconds\n",
      "Processed 790 files so far in 386.46270084381104 seconds\n",
      "Processed 800 files so far in 392.3197157382965 seconds\n",
      "Processed 810 files so far in 398.0895779132843 seconds\n",
      "Processed 820 files so far in 403.7242648601532 seconds\n",
      "Processed 830 files so far in 409.3676128387451 seconds\n",
      "Processed 840 files so far in 415.08517694473267 seconds\n",
      "Processed 850 files so far in 422.3854069709778 seconds\n",
      "Processed 860 files so far in 428.27240085601807 seconds\n",
      "Processed 870 files so far in 434.58440494537354 seconds\n",
      "Processed 880 files so far in 442.33247804641724 seconds\n",
      "Processed 890 files so far in 448.20995473861694 seconds\n",
      "Processed 900 files so far in 454.36319375038147 seconds\n",
      "Processed 910 files so far in 460.2886538505554 seconds\n",
      "Processed 920 files so far in 466.41079688072205 seconds\n",
      "Processed a batch of 920 files in 469.61916279792786 seconds\n"
     ]
    }
   ],
   "source": [
    "#creates spectrograms from audio files using generate_spectrogram\n",
    "begin_time = time.time()\n",
    "file_number = 0\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    generate_spectrogram(audio_file)\n",
    "    file_number += 1\n",
    "\n",
    "    # Print progress\n",
    "    if file_number % 10 == 0:\n",
    "        print(f\"Processed {file_number} files so far in {time.time() - begin_time} seconds\")\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"Processed a batch of {file_number} files in {time.time() - begin_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to generate audio clips by cycle\n",
    "def generate_audio_clips(audio_file, output_folder):\n",
    "    # load the audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    \n",
    "    audio_file_name = os.path.basename(audio_file)\n",
    "    # find where the timestamps of audio_file are\n",
    "    timestamps = divide_into_cycles(audio_file_name) # list\n",
    "    \n",
    "    # make an audio clip for each respiratory cycle using the timestamps\n",
    "    cycle_number = 1\n",
    "    for cycle in timestamps:\n",
    "        # take the portion of the audio that contains this respiratory cycle\n",
    "\n",
    "        # start and end time in seconds\n",
    "        start_time = cycle[0]\n",
    "        end_time = cycle[1]\n",
    "        \n",
    "        # convert the start and end times to sample indices\n",
    "        start_sample = int(start_time * sr)\n",
    "        end_sample = int(end_time * sr)\n",
    "        \n",
    "        # extract the audio segment\n",
    "        audio_segment = y[start_sample:end_sample]\n",
    "        \n",
    "        audio_clip_name = convert_type(audio_file_name, \"wav\", cycle_number)\n",
    "        \n",
    "        # save the audio clip to the output folder\n",
    "        output_path = os.path.join(output_folder, audio_clip_name)\n",
    "        write(output_path, sr, audio_segment)\n",
    "        \n",
    "        cycle_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'data/Respiratory_Sound_Database/audio_and_txt_files'\n",
    "output_folder = 'data/Respiratory_Sound_Database/clips_by_cycle'\n",
    "\n",
    "audio_files = glob.iglob(directory_path + '/*.wav', recursive=True)\n",
    "\n",
    "#generates cut audio clips by cycle and puts them in clips_by_cycle folder\n",
    "for audio_file in audio_files:\n",
    "    generate_audio_clips(audio_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            filename  \\\n",
      "0      215_1b3_Tc_sc_Meditron_cycle6   \n",
      "1      178_1b2_Al_mc_AKGC417L_cycle7   \n",
      "2     120_1b1_Pl_sc_Meditron_cycle16   \n",
      "3      166_1p1_Pl_sc_Meditron_cycle4   \n",
      "4      200_3p4_Pr_mc_AKGC417L_cycle2   \n",
      "...                              ...   \n",
      "6893   138_1p3_Tc_mc_AKGC417L_cycle4   \n",
      "6894   131_1b1_Al_sc_Meditron_cycle8   \n",
      "6895   216_1b1_Pl_sc_Meditron_cycle1   \n",
      "6896  222_1b1_Lr_sc_Meditron_cycle11   \n",
      "6897   186_2b3_Tc_mc_AKGC417L_cycle4   \n",
      "\n",
      "                                             sound_file  \\\n",
      "0     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "1     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "2     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "3     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "4     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "...                                                 ...   \n",
      "6893  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6894  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6895  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6896  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6897  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "\n",
      "                                       spectrogram_file  \n",
      "0     data/spectrograms/215_1b3_Tc_sc_Meditron_cycle...  \n",
      "1     data/spectrograms/178_1b2_Al_mc_AKGC417L_cycle...  \n",
      "2     data/spectrograms/120_1b1_Pl_sc_Meditron_cycle...  \n",
      "3     data/spectrograms/166_1p1_Pl_sc_Meditron_cycle...  \n",
      "4     data/spectrograms/200_3p4_Pr_mc_AKGC417L_cycle...  \n",
      "...                                                 ...  \n",
      "6893  data/spectrograms/138_1p3_Tc_mc_AKGC417L_cycle...  \n",
      "6894  data/spectrograms/131_1b1_Al_sc_Meditron_cycle...  \n",
      "6895  data/spectrograms/216_1b1_Pl_sc_Meditron_cycle...  \n",
      "6896  data/spectrograms/222_1b1_Lr_sc_Meditron_cycle...  \n",
      "6897  data/spectrograms/186_2b3_Tc_mc_AKGC417L_cycle...  \n",
      "\n",
      "[6898 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# get the list of sound files\n",
    "sound_files = glob.glob('data/Respiratory_Sound_Database/clips_by_cycle/*.wav')\n",
    "\n",
    "# get the list of spectrogram files\n",
    "spectrogram_files = glob.glob('data/spectrograms/*.jpg')\n",
    "\n",
    "# create a DataFrame for sound files\n",
    "df_sound = pd.DataFrame({\n",
    "    'filename': [os.path.splitext(os.path.basename(x))[0] for x in sound_files],\n",
    "    'sound_file': sound_files\n",
    "})\n",
    "\n",
    "# create a DataFrame for spectrogram files\n",
    "df_spectrogram = pd.DataFrame({\n",
    "    'filename': [os.path.splitext(os.path.basename(x))[0] for x in spectrogram_files],\n",
    "    'spectrogram_file': spectrogram_files\n",
    "})\n",
    "\n",
    "# merge the DataFrames on the 'filename' column\n",
    "df = pd.merge(df_sound, df_spectrogram, on='filename')\n",
    "\n",
    "# print the DataFrame\n",
    "print(df)\n",
    "\n",
    "#df now contains filename, sound_file, and spectrogram_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data=pd.read_csv('data/Respiratory_Sound_Database/patient_diagnosis.csv',names=['pid','disease'])\n",
    "path='data/Respiratory_Sound_Database/audio_and_txt_files/'\n",
    "files=[s.split('.')[0] for s in os.listdir(path) if '.txt' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilenameInfo(file):\n",
    "    return file.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_data=[]\n",
    "for file in files:\n",
    "    data=pd.read_csv(path + file + '.txt',sep='\\t',names=['start','end','crackles','wheezes'])\n",
    "    name_data=getFilenameInfo(file)\n",
    "    data['pid']=name_data[0]\n",
    "    data['mode']=name_data[-2]\n",
    "    data['filename']=file\n",
    "    files_data.append(data)\n",
    "files_df=pd.concat(files_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         filename  \\\n",
      "0   215_1b3_Tc_sc_Meditron_cycle6   \n",
      "1   178_1b2_Al_mc_AKGC417L_cycle7   \n",
      "2  120_1b1_Pl_sc_Meditron_cycle16   \n",
      "3   166_1p1_Pl_sc_Meditron_cycle4   \n",
      "4   200_3p4_Pr_mc_AKGC417L_cycle2   \n",
      "\n",
      "                                          sound_file  \\\n",
      "0  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "1  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "2  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "3  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "4  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "\n",
      "                                    spectrogram_file  \n",
      "0  data/spectrograms/215_1b3_Tc_sc_Meditron_cycle...  \n",
      "1  data/spectrograms/178_1b2_Al_mc_AKGC417L_cycle...  \n",
      "2  data/spectrograms/120_1b1_Pl_sc_Meditron_cycle...  \n",
      "3  data/spectrograms/166_1p1_Pl_sc_Meditron_cycle...  \n",
      "4  data/spectrograms/200_3p4_Pr_mc_AKGC417L_cycle...  \n",
      "   start    end  crackles  wheezes  pid mode                filename disease\n",
      "0  0.022  0.364         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n",
      "1  0.364  2.436         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n",
      "2  2.436  4.636         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n",
      "3  4.636  6.793         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n",
      "4  6.793  8.750         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n"
     ]
    }
   ],
   "source": [
    "patient_data.pid=patient_data.pid.astype('int32')\n",
    "files_df.pid=files_df.pid.astype('int32')\n",
    "data=pd.merge(files_df,patient_data,on='pid')\n",
    "print(df.head())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       start     end  crackles  wheezes  pid mode         disease  \\\n",
      "0      0.022   0.364         0        0  148   sc            URTI   \n",
      "1      0.364   2.436         0        0  148   sc            URTI   \n",
      "2      2.436   4.636         0        0  148   sc            URTI   \n",
      "3      4.636   6.793         0        0  148   sc            URTI   \n",
      "4      6.793   8.750         0        0  148   sc            URTI   \n",
      "...      ...     ...       ...      ...  ...  ...             ...   \n",
      "6893  16.946  19.156         1        0  130   mc            COPD   \n",
      "6894   0.022   3.450         0        0  116   sc  Bronchiectasis   \n",
      "6895   3.450  10.507         0        1  116   sc  Bronchiectasis   \n",
      "6896  10.507  17.336         0        1  116   sc  Bronchiectasis   \n",
      "6897  17.336  19.950         0        0  116   sc  Bronchiectasis   \n",
      "\n",
      "                           filename  cycle_number  \n",
      "0     148_1b1_Al_sc_Meditron_cycle1             1  \n",
      "1     148_1b1_Al_sc_Meditron_cycle2             2  \n",
      "2     148_1b1_Al_sc_Meditron_cycle3             3  \n",
      "3     148_1b1_Al_sc_Meditron_cycle4             4  \n",
      "4     148_1b1_Al_sc_Meditron_cycle5             5  \n",
      "...                             ...           ...  \n",
      "6893  130_2b3_Al_mc_AKGC417L_cycle9             9  \n",
      "6894  116_1b2_Pl_sc_Meditron_cycle1             1  \n",
      "6895  116_1b2_Pl_sc_Meditron_cycle2             2  \n",
      "6896  116_1b2_Pl_sc_Meditron_cycle3             3  \n",
      "6897  116_1b2_Pl_sc_Meditron_cycle4             4  \n",
      "\n",
      "[6898 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a new column 'filename_cycle'\n",
    "data['filename_cycle'] = data.groupby('filename').cumcount() + 1\n",
    "\n",
    "# concatenate 'filename' and 'filename_cycle' to create a new column\n",
    "data['filename_cycle'] = data['filename'] + '_cycle' + data['filename_cycle'].astype(str)\n",
    "\n",
    "data['cycle_number'] = data['filename_cycle'].apply(lambda x: int(x.split('_cycle')[-1]))\n",
    "\n",
    "data = data.drop('filename', axis=1)\n",
    "\n",
    "# rename the 'filename_cycle' column to 'filename'\n",
    "data = data.rename(columns={'filename_cycle': 'filename'})\n",
    "\n",
    "# print the DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the DataFrames on the 'filename' column\n",
    "merged_df = pd.merge(df, data, on='filename')\n",
    "\n",
    "#rearrange columns \n",
    "new_columns_order = ['filename', 'pid', 'cycle_number', 'start', 'end', 'crackles', 'wheezes', 'mode', 'disease', 'sound_file', 'spectrogram_file']\n",
    "merged_df = merged_df[new_columns_order]\n",
    "\n",
    "#sort rows based on patient id then cycle number\n",
    "merged_df = merged_df.sort_values(['pid', 'cycle_number'])\n",
    "\n",
    "# save the DataFrame to a CSV file\n",
    "merged_df.to_csv('data/data_by_cycle.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df = pd.read_csv('data/demographic_info.txt', sep=' ', header=None)\n",
    "demographic_df.columns = ['pid', 'age', 'sex', 'adult_BMI', 'child_weight', 'child_height']\n",
    "\n",
    "# Create a mask to filter rows where weight and height are not NA\n",
    "mask = (demographic_df['child_weight'].notna()) & (demographic_df['child_height'].notna())\n",
    "\n",
    "# Calculate child BMI using weight and height\n",
    "demographic_df.loc[mask, 'child_BMI'] = demographic_df.loc[mask, 'child_weight'] / (demographic_df.loc[mask, 'child_height'] / 100) ** 2\n",
    "demographic_df['child_BMI'] = demographic_df['child_BMI'].round(2)\n",
    "# BEGIN: New Cell\n",
    "\n",
    "# Create a new column 'bmi' based on 'adult_BMI' and 'child_BMI'\n",
    "demographic_df['bmi'] = demographic_df['adult_BMI'].fillna(demographic_df['child_BMI'])\n",
    "# END: New Cell\n",
    "\n",
    "second_merge=pd.merge(merged_df,demographic_df,on='pid')\n",
    "second_merge.to_csv('data/data_by_cycle_and_demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pid2 recording_index chest_location acquisition_position  \\\n",
      "0     101             1b1             Pr                   sc   \n",
      "1     101             1b1             Al                   sc   \n",
      "2     101             1b1             Pr                   sc   \n",
      "3     101             1b1             Al                   sc   \n",
      "4     101             1b1             Pr                   sc   \n",
      "...   ...             ...            ...                  ...   \n",
      "6893  226             1b1             Al                   sc   \n",
      "6894  226             1b1             Al                   sc   \n",
      "6895  226             1b1             Ll                   sc   \n",
      "6896  226             1b1             Pl                   sc   \n",
      "6897  226             1b1             Pl                   sc   \n",
      "\n",
      "     recording_equipment cycle_number2                        filename  \n",
      "0               Meditron             1   101_1b1_Pr_sc_Meditron_cycle1  \n",
      "1               Meditron             1   101_1b1_Al_sc_Meditron_cycle1  \n",
      "2               Meditron             2   101_1b1_Pr_sc_Meditron_cycle2  \n",
      "3               Meditron             2   101_1b1_Al_sc_Meditron_cycle2  \n",
      "4               Meditron             3   101_1b1_Pr_sc_Meditron_cycle3  \n",
      "...                  ...           ...                             ...  \n",
      "6893            Meditron             9   226_1b1_Al_sc_Meditron_cycle9  \n",
      "6894            Meditron            10  226_1b1_Al_sc_Meditron_cycle10  \n",
      "6895            Meditron            10  226_1b1_Ll_sc_Meditron_cycle10  \n",
      "6896            LittC2SE            10  226_1b1_Pl_sc_LittC2SE_cycle10  \n",
      "6897            LittC2SE            11  226_1b1_Pl_sc_LittC2SE_cycle11  \n",
      "\n",
      "[6898 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "filenames = second_merge.filename\n",
    "filename_df = pd.DataFrame()\n",
    "\n",
    "filename_df['pid2'] = [re.findall(r'^(\\d+)_', filename)[0] for filename in filenames]\n",
    "\n",
    "#adds the recording index to the data frame\n",
    "recording_index_list = []\n",
    "for filename in filenames:\n",
    "    match = re.findall(r'\\d+_(\\d+[a-z]\\d+)_', filename)\n",
    "    if match:\n",
    "        recording_index_list.append(match[0])\n",
    "    else:\n",
    "        recording_index_list.append(None)\n",
    "filename_df['recording_index'] = recording_index_list\n",
    "\n",
    "\n",
    "chest_location_list = []\n",
    "for filename in filenames:\n",
    "    match = re.findall(r'_([A-Z][a-z])_', filename)\n",
    "    if match:\n",
    "        chest_location_list.append(match[0])\n",
    "    else:\n",
    "        chest_location_list.append(None)\n",
    "\n",
    "filename_df['chest_location'] = chest_location_list\n",
    "\n",
    "\n",
    "\n",
    "acquisition_position_list = []\n",
    "for filename in filenames:\n",
    "    match = re.findall(r'_([a-z][a-z])_', filename)\n",
    "    if match:\n",
    "        acquisition_position_list.append(match[0])\n",
    "    else:\n",
    "        acquisition_position_list.append(None)\n",
    "\n",
    "filename_df['acquisition_position'] = acquisition_position_list\n",
    "\n",
    "possible_recording_equipment = [\"AKGC417L\", \"LittC2SE\", \"Litt3200\", \"Meditron\"]\n",
    "\n",
    "# Create an empty list to store the recording equipment\n",
    "recording_equipment_list = []\n",
    "\n",
    "# Loop through each filename\n",
    "for filename in filenames:\n",
    "    # Extract the recording equipment from the filename\n",
    "    recording_equipment = None\n",
    "    for equipment in possible_recording_equipment:\n",
    "        if equipment in filename:\n",
    "            recording_equipment = equipment\n",
    "            break\n",
    "    \n",
    "    # Append the recording equipment to the list\n",
    "    recording_equipment_list.append(recording_equipment)\n",
    "\n",
    "# Create a DataFrame with the recording equipment list\n",
    "filename_df['recording_equipment'] = recording_equipment_list\n",
    "\n",
    "filename_df['cycle_number2'] = [re.findall(r'cycle(\\d+)', filename)[0] for filename in filenames]\n",
    "filename_df['filename'] = filenames\n",
    "print(filename_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge_df = pd.merge(second_merge, filename_df, on='filename')\n",
    "final_merge_df = final_merge_df.drop(columns=['filename', 'cycle_number2', 'pid2'])\n",
    "final_merge_df.to_csv('data/data_complete.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# new directories to be created\n",
    "downsampled_clips = \"data/downsampled_clips\"\n",
    "\n",
    "# create the directories\n",
    "os.makedirs(downsampled_clips, exist_ok=True)\n",
    "\n",
    "# define a function to apply a Butterworth band-pass filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    if low > 1: low = 1\n",
    "    if high > 1: high = 1\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "# specify the directory containing the original audio files\n",
    "directory = 'data/Respiratory_Sound_Database/audio_and_txt_files'\n",
    "output_folder = 'data/downsampled_clips'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    # check if the file is an audio file\n",
    "    if filename.endswith('.wav'):\n",
    "        # load the audio file with a sample rate of 4000 Hz\n",
    "        y, sr = librosa.load(os.path.join(directory, filename), sr=4000)\n",
    "        \n",
    "        # apply the Butterworth band-pass filter\n",
    "        y = butter_bandpass_filter(y, lowcut=10, highcut=1800, fs=sr)\n",
    "        \n",
    "        # apply standard normalization\n",
    "        y = (y - np.mean(y)) / np.std(y)\n",
    "        \n",
    "        # save the processed audio file to the new directory\n",
    "        sf.write(os.path.join(output_folder, filename), y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# new directories to be created\n",
    "normalized_spectrograms = \"data/normalized_spectrograms\"\n",
    "\n",
    "# create the directories\n",
    "os.makedirs(normalized_spectrograms, exist_ok=True)\n",
    "\n",
    "output_folder = normalized_spectrograms\n",
    "directory = \"data/downsampled_clips\"\n",
    "directory_path = 'data/Respiratory_Sound_Database/audio_and_txt_files'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    # check if the file is an audio file\n",
    "    if filename.endswith('.wav'):\n",
    "        # generate the spectrogram for the audio file\n",
    "        generate_spectrogram(os.path.join(directory, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bfe9e5435af0ab44c34ef3869879b94f2b4eaf222b17b3e6cb7962639383bf17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
